#!/usr/bin/env ruby
require "bundler/setup"
require_relative "../lib/shoreline/consumer"
require "date"
require "json"
require "logger"
require "net/http"
require "opentelemetry/sdk"

# don't buffer log output
$stdout.sync = true

puts 'Loading environment...'
require File.expand_path('../config/environment', __dir__)
puts "Running in #{Rails.env} mode..."

logger = Logger.new($stdout)
logger.level = ENV.fetch("LOG_LEVEL") { Logger::INFO }

unless ENV["OTEL_SDK_DISABLED"] == "true"
  OpenTelemetry::SDK.configure do |c|
    c.service_name = "surfliner-shoreline-consumer"
    c.use_all # enables auto instrumentation for Bunny, Net::HTTP, etc...
  end
end

Tracer = OpenTelemetry.tracer_provider.tracer("ShorelineConsumerTracer")

# @param [URI] uri
def fetch(uri:, logger:)
  req = Net::HTTP::Get.new(uri)
  req["Accept"] = "application/ld+json;profile=\"#{ENV.fetch('SHORELINE_METADATA_PROFILE', "tag:surfliner.gitlab.io,2022:api/aardvark")}\""
  req["User-Agent"] = ENV.fetch("USER_AGENT_PRODUCT_NAME", "surfliner.shoreline")
  logger.debug "Querying #{uri} ..."

  res = Net::HTTP.start(uri.hostname, uri.port, use_ssl: uri.scheme == "https") { |http|
    http.request(req)
  }

  case res
  when Net::HTTPSuccess
    res.body
  when Net::HTTPRedirection
    logger.debug "Got a 30x response: #{res}"
    fetch(uri: URI(res['location']), logger: logger)
  else
    logger.debug "Got a non-success HTTP response:"
    logger.debug res.inspect

    raise "Failed to fetch data from Superskunk"
  end
end

connection = Shoreline::Consumer::Connection.new(logger: logger)

connection.open do |queue|
  queue.subscribe(block: true) do |_delivery_info, _properties, payload|
    trace_span = Tracer.start_span("shoreline consumer message")
    logger.info(" [ ï€Œ ] message received with payload: #{payload}")
    payload_data = JSON.parse(payload)
    payload_resource_url = payload_data["resourceUrl"]
    raise "Payload resourceUrl is not defined" unless payload_resource_url

    payload_status = payload_data["status"]
    raise "Payload status is not defined" unless payload_status
    logger.debug("Payload status for #{payload_resource_url} is #{payload_status}")

    trace_span.add_attributes(
      "surfliner.message.status" => payload_status.to_s,
      "surfliner.resource_uri" => payload_resource_url.to_s
    )

    uri = URI(payload_resource_url)

    begin
      case payload_status
      when "published", "updated"
        record_data = JSON.parse(fetch(uri: uri, logger: logger))

        # TODO: teach the importer how to handle multiple shapefiles per record?
        shapefile_url = record_data["_file_urls"]&.first

        logger.info("Persisting item #{payload_resource_url}")
        logger.debug("#{payload_resource_url} responded with #{record_data}")

        Importer.ingest(metadata: record_data.except("_file_urls"), shapefile_url: shapefile_url)
      when "unpublished", "deleted"
        logger.info("Deleting item #{payload_resource_url}")
        resource_id = payload_resource_url.split("/").last
        Importer.delete(id: resource_id)
      else
        msg = "Invalid payload status #{payload_status} received for #{payload_resource_url}"
        logger.error(msg)
        trace_span&.status = OpenTelemetry::Trace::Status.error(msg)
      end
    rescue => e
      logger.error("Error: #{e}")
      trace_span&.record_exception(e)
      trace_span&.status = OpenTelemetry::Trace::Status.error("Unhandled exception of type: #{e.class}")
    ensure
      trace_span&.finish
    end
  ensure
    trace_span&.finish
  end
end
