#!/usr/bin/env ruby
require "bundler/inline"
require "date"
require "json"
require "logger"

logger = Logger.new($stdout)
logger.level = ENV.fetch("LOG_LEVEL") { Logger::INFO }

gemfile do
  source "https://rubygems.org"

  gem "bunny", "2.19.0"
  gem "pg", "1.3.0"
  gem "sequel", "5.53.0"
end

rabbitmq_host = ENV.fetch("RABBITMQ_HOST")
rabbitmq_user = ENV.fetch("RABBITMQ_USERNAME")
rabbitmq_password = ENV.fetch("RABBITMQ_PASSWORD")
rabbitmq_port = ENV.fetch("RABBITMQ_NODE_PORT_NUMBER")
rabbitmq_topic = ENV.fetch("RABBITMQ_TOPIC")
rabbitmq_routing_key = ENV.fetch("RABBITMQ_TIDEWATER_ROUTING_KEY")

# Responsible for writing changes from superskunk to the tidewater database
class Persister
  # Entrypoint method to support both creating and updating OaiItems
  # @param record [Hash] Metadata for a given record from the superskunk api
  def self.create_or_update(record:)
    if db.where(source_iri: record["source_iri"]).empty?
      create(record: record)
    else
      update(record: record)
    end
  end

  # Creates a new OaiItem
  # @param record [Hash] Metadata for a given record from the superskunk api
  def self.create(record:)
    timestamp = DateTime.now.to_s
    record["created_at"] = timestamp
    record["updated_at"] = timestamp

    db.insert(record)
  end

  # Updates an existing OaiItem
  # @param record [Hash] Metadata for a given record from the superskunk api
  def self.update(record:)
    timestamp = DateTime.now.to_s
    record["updated_at"] = timestamp

    # if columns are missing from record, set them to nil as they may have been deleted upstream
    empty_column_values = db.columns.each_with_object({}) { |e, h| h[e] = nil }
    empty_column_values.delete(:id) # internal database identifier should never be updated
    empty_column_values.delete(:created_at) # created timestamp should never be updated
    record.merge!(empty_column_values) { |_k, record_value, _empty_value| record_value }

    db.where(source_iri: record["source_iri"]).update(record)
  end

  # Deletes an OaiItem
  # @param source_iri [String] Unique identifier for an OaiItem
  def self.delete(source_iri:)
    db.where(source_iri: source_iri).delete
  end

  # Construct a Sequel instance targeting the oai_items database
  # @return [Sequel::Dataset] instance on oai_items table for performing queries
  def self.db
    @db ||= Sequel.postgres(host: ENV["POSTGRES_HOST"],
      port: ENV["POSTGRES_PORT"],
      database: ENV["POSTGRES_DB"],
      user: ENV["POSTGRES_USER"],
      password: ENV["POSTGRES_PASSWORD"])[:oai_items]
  end
end

connection_url = "amqp://#{rabbitmq_user}:#{rabbitmq_password}@#{rabbitmq_host}:#{rabbitmq_port}".freeze
logger.info("Rabbitmq message broker connection url: #{connection_url.sub(rabbitmq_password, "REDACTED")}")

begin
  connection = Bunny.new(connection_url)
  connection.start
rescue Bunny::TCPConnectionFailed
  logger.error("Connection to #{rabbitmq_host} failed")
rescue Bunny::PossibleAuthenticationFailureError
  logger.error("Failed to authenticate to #{rabbitmq_host}")
end

channel = connection.create_channel
exchange = channel.topic(rabbitmq_topic)
queue = channel.queue("", exclusive: true)
queue.bind(exchange, routing_key: rabbitmq_routing_key)

logger.info(" [*] Waiting for updates. To exit press CTRL+C")

begin
  queue.subscribe(block: true) do |delivery_info, properties, payload|
    logger.info(" [x] message received with payload: #{payload}")
    payload_data = JSON.parse(payload)
    payload_resource_url = payload_data["resourceUrl"]
    raise "Payload resourceUrl is not defined" unless payload_resource_url

    # TODO: use the payload_resource_url to get the data
    # payload_record = GET request to superskunk
    payload_record = {}
    Persister.create_or_update(record: payload_record)
  end
rescue Interrupt => _
  channel.close
  connection.close
end
